{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled21.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOhHMS857ZtlQLRop3OjRl8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prajwalr96/TenserFlow_Learning/blob/master/LSTM_TimeSeries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IABEMlSmY4Hu"
      },
      "source": [
        "# LSTM TimeSeries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOjujz601HcS",
        "outputId": "907cce71-1182-4fca-f3de-20d4786b4434"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(tf.__version__)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zswl7jRtGzkk"
      },
      "source": [
        "def plot_series(time, series, format=\"-\", start=0, end=None):\n",
        "    plt.plot(time[start:end], series[start:end], format)\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Value\")\n",
        "    plt.grid(True)\n",
        "\n",
        "def trend(time, slope=0):\n",
        "    return slope * time\n",
        "\n",
        "def seasonal_pattern(season_time):\n",
        "    \"\"\"Just an arbitrary pattern, you can change it if you wish\"\"\"\n",
        "    return np.where(season_time < 0.4,\n",
        "                    np.cos(season_time * 2 * np.pi),\n",
        "                    1 / np.exp(3 * season_time))\n",
        "\n",
        "def seasonality(time, period, amplitude=1, phase=0):\n",
        "    \"\"\"Repeats the same pattern at each period\"\"\"\n",
        "    season_time = ((time + phase) % period) / period\n",
        "    return amplitude * seasonal_pattern(season_time)\n",
        "\n",
        "def noise(time, noise_level=1, seed=None):\n",
        "    rnd = np.random.RandomState(seed)\n",
        "    return rnd.randn(len(time)) * noise_level\n",
        "\n",
        "time = np.arange(4 * 365 + 1, dtype=\"float32\")\n",
        "baseline = 10\n",
        "series = trend(time, 0.1)  \n",
        "baseline = 10\n",
        "amplitude = 40\n",
        "slope = 0.05\n",
        "noise_level = 5\n",
        "\n",
        "# Create the series\n",
        "series = baseline + trend(time, slope) + seasonality(time, period=365, amplitude=amplitude)\n",
        "# Update with noise\n",
        "series += noise(time, noise_level, seed=42)\n",
        "\n",
        "split_time = 1000\n",
        "time_train = time[:split_time]\n",
        "x_train = series[:split_time]\n",
        "time_valid = time[split_time:]\n",
        "x_valid = series[split_time:]\n",
        "\n",
        "window_size = 20\n",
        "batch_size = 32\n",
        "shuffle_buffer_size = 1000"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sTTIOCbyShY"
      },
      "source": [
        "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(series)\n",
        "  dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
        "  dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
        "  dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1]))\n",
        "  dataset = dataset.batch(batch_size).prefetch(1)\n",
        "  return dataset"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1Hl39rklkLm",
        "outputId": "4758d54f-a61e-4f71-c376-dceb8c626ede"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.random.set_seed(51)\n",
        "np.random.seed(51)\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
        "                      input_shape=[None]),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Lambda(lambda x: x * 100.0)\n",
        "])\n",
        "\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: 1e-8 * 10**(epoch / 20))\n",
        "optimizer = tf.keras.optimizers.SGD(lr=1e-8, momentum=0.9)\n",
        "model.compile(loss=tf.keras.losses.Huber(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\"])\n",
        "history = model.fit(dataset, epochs=100, callbacks=[lr_schedule])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "31/31 [==============================] - 6s 23ms/step - loss: 21.9679 - mae: 22.4630\n",
            "Epoch 2/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 21.0787 - mae: 21.5699\n",
            "Epoch 3/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 19.9720 - mae: 20.4666\n",
            "Epoch 4/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 20.5891 - mae: 21.0813\n",
            "Epoch 5/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 20.2777 - mae: 20.7735\n",
            "Epoch 6/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 19.6437 - mae: 20.1366\n",
            "Epoch 7/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 18.2940 - mae: 18.7848\n",
            "Epoch 8/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 17.2657 - mae: 17.7576\n",
            "Epoch 9/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 17.4906 - mae: 17.9840\n",
            "Epoch 10/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 16.8689 - mae: 17.3590\n",
            "Epoch 11/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 16.4565 - mae: 16.9496\n",
            "Epoch 12/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 16.1107 - mae: 16.6051\n",
            "Epoch 13/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 15.9437 - mae: 16.4400\n",
            "Epoch 14/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 16.2057 - mae: 16.7015\n",
            "Epoch 15/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 16.2997 - mae: 16.7944\n",
            "Epoch 16/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 15.2008 - mae: 15.6951\n",
            "Epoch 17/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 14.6605 - mae: 15.1572\n",
            "Epoch 18/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 14.7761 - mae: 15.2720\n",
            "Epoch 19/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 14.4512 - mae: 14.9444\n",
            "Epoch 20/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 14.5195 - mae: 15.0117\n",
            "Epoch 21/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 13.5757 - mae: 14.0695\n",
            "Epoch 22/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 13.5288 - mae: 14.0247\n",
            "Epoch 23/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 12.7991 - mae: 13.2927\n",
            "Epoch 24/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 12.9368 - mae: 13.4304\n",
            "Epoch 25/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 13.4398 - mae: 13.9332\n",
            "Epoch 26/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 12.5766 - mae: 13.0663\n",
            "Epoch 27/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 12.4469 - mae: 12.9387\n",
            "Epoch 28/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 12.0455 - mae: 12.5353\n",
            "Epoch 29/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 11.7434 - mae: 12.2307\n",
            "Epoch 30/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 12.1353 - mae: 12.6266\n",
            "Epoch 31/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 10.5933 - mae: 11.0832\n",
            "Epoch 32/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 11.3526 - mae: 11.8427\n",
            "Epoch 33/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 10.6144 - mae: 11.1091\n",
            "Epoch 34/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 10.3742 - mae: 10.8633\n",
            "Epoch 35/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 10.0720 - mae: 10.5541\n",
            "Epoch 36/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 9.6692 - mae: 10.1608\n",
            "Epoch 37/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 9.6828 - mae: 10.1720\n",
            "Epoch 38/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 9.5939 - mae: 10.0829\n",
            "Epoch 39/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 9.1433 - mae: 9.6265\n",
            "Epoch 40/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 8.2328 - mae: 8.7213\n",
            "Epoch 41/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 8.5004 - mae: 8.9857\n",
            "Epoch 42/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 7.7835 - mae: 8.2651\n",
            "Epoch 43/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 7.4934 - mae: 7.9763\n",
            "Epoch 44/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 7.2139 - mae: 7.6977\n",
            "Epoch 45/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 7.2607 - mae: 7.7492\n",
            "Epoch 46/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 6.7730 - mae: 7.2547\n",
            "Epoch 47/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 6.8849 - mae: 7.3723\n",
            "Epoch 48/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 6.4202 - mae: 6.8985\n",
            "Epoch 49/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 6.2204 - mae: 6.6972\n",
            "Epoch 50/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 6.1395 - mae: 6.6177\n",
            "Epoch 51/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 5.9802 - mae: 6.4566\n",
            "Epoch 52/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 5.5420 - mae: 6.0235\n",
            "Epoch 53/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 5.9445 - mae: 6.4288\n",
            "Epoch 54/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 5.4762 - mae: 5.9533\n",
            "Epoch 55/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 5.5387 - mae: 6.0098\n",
            "Epoch 56/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 5.0777 - mae: 5.5511\n",
            "Epoch 57/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 5.2487 - mae: 5.7285\n",
            "Epoch 58/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 5.6203 - mae: 6.1054\n",
            "Epoch 59/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 5.2632 - mae: 5.7434\n",
            "Epoch 60/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 5.1216 - mae: 5.5905\n",
            "Epoch 61/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 5.2779 - mae: 5.7550\n",
            "Epoch 62/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 5.3425 - mae: 5.8233\n",
            "Epoch 63/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 5.1201 - mae: 5.5968\n",
            "Epoch 64/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 5.0238 - mae: 5.4966\n",
            "Epoch 65/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 4.8078 - mae: 5.2898\n",
            "Epoch 66/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 5.4764 - mae: 5.9609\n",
            "Epoch 67/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 6.0091 - mae: 6.4906\n",
            "Epoch 68/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 4.9516 - mae: 5.4324\n",
            "Epoch 69/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 5.8167 - mae: 6.3011\n",
            "Epoch 70/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 5.4645 - mae: 5.9489\n",
            "Epoch 71/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 5.3114 - mae: 5.7928\n",
            "Epoch 72/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 5.4494 - mae: 5.9264\n",
            "Epoch 73/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 6.1336 - mae: 6.6140\n",
            "Epoch 74/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 5.7203 - mae: 6.1993\n",
            "Epoch 75/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 4.9408 - mae: 5.4204\n",
            "Epoch 76/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 5.5451 - mae: 6.0282\n",
            "Epoch 77/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 7.1438 - mae: 7.6282\n",
            "Epoch 78/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 5.6744 - mae: 6.1588\n",
            "Epoch 79/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 5.1942 - mae: 5.6726\n",
            "Epoch 80/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 4.7828 - mae: 5.2631\n",
            "Epoch 81/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 6.4667 - mae: 6.9492\n",
            "Epoch 82/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 5.8926 - mae: 6.3785\n",
            "Epoch 83/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 6.7402 - mae: 7.2248\n",
            "Epoch 84/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 6.1964 - mae: 6.6825\n",
            "Epoch 85/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 7.8645 - mae: 8.3526\n",
            "Epoch 86/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 7.3870 - mae: 7.8709\n",
            "Epoch 87/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 6.3550 - mae: 6.8450\n",
            "Epoch 88/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 9.4090 - mae: 9.8978\n",
            "Epoch 89/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 7.6073 - mae: 8.0948\n",
            "Epoch 90/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 8.6020 - mae: 9.0924\n",
            "Epoch 91/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 10.1672 - mae: 10.6591\n",
            "Epoch 92/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 6.5734 - mae: 7.0540\n",
            "Epoch 93/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 11.0945 - mae: 11.5857\n",
            "Epoch 94/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 9.5562 - mae: 10.0454\n",
            "Epoch 95/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 9.2937 - mae: 9.7868\n",
            "Epoch 96/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 8.4699 - mae: 8.9561\n",
            "Epoch 97/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 11.9757 - mae: 12.4700\n",
            "Epoch 98/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 8.5256 - mae: 9.0168\n",
            "Epoch 99/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 8.3632 - mae: 8.8468\n",
            "Epoch 100/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 11.6255 - mae: 12.1136\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "AkBsrsXMzoWR",
        "outputId": "5ef920b7-9404-4786-ab0a-6a9050443ef7"
      },
      "source": [
        "plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\n",
        "plt.axis([1e-8, 1e-4, 0, 30])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1e-08, 0.0001, 0.0, 30.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uh-97bpLZCA"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.random.set_seed(51)\n",
        "np.random.seed(51)\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
        "                      input_shape=[None]),\n",
        "   tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Lambda(lambda x: x * 100.0)\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.SGD(lr=1e-5, momentum=0.9),metrics=[\"mae\"])\n",
        "history = model.fit(dataset,epochs=500,verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icGDaND7z0ne"
      },
      "source": [
        "forecast = []\n",
        "results = []\n",
        "for time in range(len(series) - window_size):\n",
        "  forecast.append(model.predict(series[time:time + window_size][np.newaxis]))\n",
        "\n",
        "forecast = forecast[split_time-window_size:]\n",
        "results = np.array(forecast)[:, 0, 0]\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plot_series(time_valid, x_valid)\n",
        "plot_series(time_valid, results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfPeqI7rz4LD"
      },
      "source": [
        "tf.keras.metrics.mean_absolute_error(x_valid, results).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUsdZB_tzDLe"
      },
      "source": [
        "import matplotlib.image  as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "mae=history.history['mae']\n",
        "loss=history.history['loss']\n",
        "\n",
        "epochs=range(len(loss)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot MAE and Loss\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, mae, 'r')\n",
        "plt.plot(epochs, loss, 'b')\n",
        "plt.title('MAE and Loss')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend([\"MAE\", \"Loss\"])\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "epochs_zoom = epochs[200:]\n",
        "mae_zoom = mae[200:]\n",
        "loss_zoom = loss[200:]\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot Zoomed MAE and Loss\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs_zoom, mae_zoom, 'r')\n",
        "plt.plot(epochs_zoom, loss_zoom, 'b')\n",
        "plt.title('MAE and Loss')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend([\"MAE\", \"Loss\"])\n",
        "\n",
        "plt.figure()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CGaYFxXNEAK"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
        "                      input_shape=[None]),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Lambda(lambda x: x * 100.0)\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.SGD(lr=1e-6, momentum=0.9))\n",
        "model.fit(dataset,epochs=100, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ3R8ysauz9e"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
        "                      input_shape=[None]),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Lambda(lambda x: x * 100.0)\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.SGD(lr=1e-6, momentum=0.9))\n",
        "model.fit(dataset,epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}